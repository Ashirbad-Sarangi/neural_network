{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36350b31-f335-440c-bb36-beb2387d208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as analytics\n",
    "import numpy as maths\n",
    "from numba import cuda , jit\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae557c2d-fe2f-4ea5-9470-de9a4f0667ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d04ec6e-9157-409c-9b61-24af821d1fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ashirbad-sarangi/Documents/Deep_Learning/assign_1/neural_network'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c68efa-5602-4bea-a046-92db220cd6f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/data1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_data \u001b[38;5;241m=\u001b[39m \u001b[43manalytics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/data1.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df_data\u001b[38;5;241m.\u001b[39mcolumns[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m df_data\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/data1.csv'"
     ]
    }
   ],
   "source": [
    "df_data = analytics.read_csv('../data/data1.csv',header = None)\n",
    "df_data.columns = ['x'+str(i) for i in df_data.columns[:-1]] + ['y']\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393dcb48-e0b2-4fe6-9ec8-3c16c51a8e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network :\n",
    "    \n",
    "    def __init__(self,df_data , number_of_neurons = [2,1], epsilon = 5e-2, alpha = 0.2, hidden_function = 'relu', output_function = 'sigmoid' , initialisation_technique = 'xavier_normal', batch_size = 15) :\n",
    "        self.number_of_hidden_layers = len(number_of_neurons) - 1\n",
    "        self.number_of_neurons = number_of_neurons\n",
    "        self.df_data = df_data\n",
    "        self.epsilon = epsilon \n",
    "        self.N = df_data.shape[0]\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        functions_list = {'relu':self.relu , 'sigmoid' : self.sigmoid , 'identity' : self.identity}\n",
    "        intialisation_list = {'xavier_normal':self.xavier_normal , 'he_normal':self.he_normal, 'xavier_uniform' : self.xavier_uniform, 'he_uniform' : self.he_uniform, 'uniform' : self.uniform }\n",
    "        loss_function_list = {'sigmoid' : self.cross_entropy , 'identity' : self.rmse }\n",
    "    \n",
    "        self.hidden = functions_list[hidden_function]\n",
    "        self.output = functions_list[output_function]\n",
    "        self.loss = loss_function_list[output_function]\n",
    "        self.initialise = intialisation_list[initialisation_technique]\n",
    "\n",
    "        if self.output == self.sigmoid and self.number_of_neurons[-1] != 1 :\n",
    "            print(\"Sigmoid must have only one neuron in the output. Please check the structure !\")\n",
    "            raise ValueError('Sigmoid must have only one neuron in the output. Please check the structure !')\n",
    "\n",
    "        if self.output == self.identity and self.number_of_neurons[-1] != 1 :\n",
    "            print(\"Regression must have only one neuron in the output. Please check the structure !\")\n",
    "            raise ValueError('Regression must have only one neuron in the output. Please check the structure !')\n",
    "\n",
    "\n",
    "    def relu(self,x) :\n",
    "        \"\"\"Hidden Activation Function\"\"\"\n",
    "        return max(0,x)\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        \"\"\"Output Function\"\"\"\n",
    "        return 1 / (1 + maths.exp(-x))\n",
    "\n",
    "    def identity(self,x):\n",
    "        return x\n",
    "\n",
    "    def calculate_derivative(self, data, func):\n",
    "        if func == self.relu :\n",
    "            if data > 0 : data = 1\n",
    "            derivative = func(data)\n",
    "\n",
    "        if func == self.sigmoid :\n",
    "            derivative = func(data) * ( 1- func(data))\n",
    "\n",
    "        if func == self.identity :\n",
    "            derivative = 1\n",
    "\n",
    "        if func == self.rmse:\n",
    "            derivative = data\n",
    "\n",
    "        if func == self.cross_entropy :\n",
    "            y = data[0]\n",
    "            fx = data[1]\n",
    "            x = data[2]\n",
    "            derivative = (y-fx)*x\n",
    "\n",
    "        return derivative\n",
    "\n",
    "    def xavier_normal(self,fan_in, fan_out):\n",
    "        mu = 0 \n",
    "        sigma = (2 / (fan_in + fan_out))**0/5\n",
    "\n",
    "        weight = maths.random.normal(mu, sigma,(fan_out, fan_in))\n",
    "        bias = maths.random.normal(mu,sigma,(fan_out,1))\n",
    "\n",
    "        return weight , bias\n",
    "\n",
    "    def he_normal(self,fan_in, fan_out):\n",
    "        mu = 0\n",
    "        sigma = (2/fan_in) ** 0.5\n",
    "        \n",
    "        weight = maths.random.normal(0,sigma,(fan_out,fan_in))\n",
    "        bias = maths.random.normal(0,sigma,(fan_out,1))\n",
    "\n",
    "        return weight , bias\n",
    "\n",
    "    def xavier_uniform(self, fan_in, fan_out) :\n",
    "        weight = maths.random.uniform(-( 6 ** 0.5 / (fan_in + fan_out)) ** 0.5 , (6 / (fan_in + fan_out)) ** 0.5, (fan_out,fan_in))\n",
    "        bias = maths.random.uniform(-( 6 ** 0.5 / (fan_in + fan_out)) ** 0.5 , (6 / (fan_in + fan_out)) ** 0.5, (fan_out,1))\n",
    "\n",
    "        return weight, bias\n",
    "        \n",
    "    def he_uniform(self, fan_in, fan_out) :\n",
    "        weight = maths.random.uniform(-( 6 ** 0.5 / fan_in) ** 0.5 , (6 / fan_out) ** 0.5, (fan_out,fan_in))\n",
    "        bias = maths.random.uniform(-( 6 ** 0.5 / fan_in) ** 0.5 , (6 / fan_out) ** 0.5, (fan_out,1))\n",
    "\n",
    "        return weight, bias\n",
    "\n",
    "    \n",
    "    def uniform(self, fan_in, fan_out) :\n",
    "        weight = maths.random.uniform(-1/fan_in**0.5 , 1/fan_in**0.5,(fan_out,fan_in))\n",
    "        bias = maths.random.uniform(-1/fan_in**0.5 , 1/fan_in**0.5,(fan_out,1))\n",
    "\n",
    "        return weight, bias\n",
    "\n",
    "    def rmse(y,x):\n",
    "        return (y-x)**2\n",
    "\n",
    "    def cross_entropy(y,x):\n",
    "        return -(y*maths.log(abs(x)) + (1-y)*maths.log(abs(1-x)))\n",
    "    \n",
    "    \n",
    "    def initialisation(self):\n",
    "        weights = []\n",
    "        bias = []\n",
    "        for l in range(self.number_of_hidden_layers + 1):\n",
    "            if l == 0 : previous_layer = df_data.shape[1] - 1\n",
    "            else : previous_layer = self.number_of_neurons[l-1]\n",
    "            present_layer = self.number_of_neurons[l]\n",
    "\n",
    "            \n",
    "            weight , bia = self.initialise(previous_layer , present_layer)    \n",
    "            \n",
    "            weights.append(weight)\n",
    "            bias.append(bia)\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "\n",
    "    def forward_propagation(self,x):\n",
    "        activations = []\n",
    "        activations.append(x)   # inputdata point is the initial activation\n",
    "        \n",
    "        hidden_layers = []\n",
    "        \n",
    "        for l in range(self.number_of_hidden_layers):\n",
    "            neurons = self.weights[l] @ activations[l] + self.bias[l]   # it actually should be activations[l+1] but because indexing in python starts from 0, so it is activations[l]\n",
    "            activation = maths.matrix([self.hidden(float(neuron)) for neuron in neurons]).reshape(-1,1)\n",
    "            hidden_layers.append(neurons)\n",
    "            activations.append(activation)\n",
    "   \n",
    "        neurons = self.weights[-1] @ activations[-1] + self.bias[-1]\n",
    "        outputs = maths.matrix([float(self.output(x)) for x in neurons]).reshape(-1,1)\n",
    "        hidden_layers.append(neurons)\n",
    "        activations.append(outputs)\n",
    "        \n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.activations = activations\n",
    "\n",
    "\n",
    "    def backward_propagation(self,x,y) :\n",
    "      \n",
    "        deltas = []\n",
    "        \n",
    "        if self.loss == self.rmse :\n",
    "            t = 2*(self.activations[-1] - y)\n",
    "            \n",
    "        if self.loss == self.cross_entropy :\n",
    "            t = (y, self.activations[-1] , self.hidden_layers[-1])\n",
    "\n",
    "        \n",
    "        loss_change_wrt_output = self.calculate_derivative(t,self.loss)\n",
    "\n",
    "        outputs = maths.matrix([float(self.calculate_derivative(x,self.output)) for x in self.hidden_layers[-1]]).reshape(loss_change_wrt_output.shape)\n",
    "        delta = maths.multiply(loss_change_wrt_output , outputs)   # change in loss wrt output layer\n",
    "        deltas.append(delta)\n",
    "\n",
    "        grad_weights = []\n",
    "        grad_biases = []\n",
    "\n",
    "        for l in range(self.number_of_hidden_layers , -1, -1 ): # it is actually running from Output layer to the first hidden layer. Due to indexing convention, loop starts from number_of_hidden_layers and goes till 0\n",
    "            grad_weight = deltas[0] @ self.activations[l].T\n",
    "            grad_bias = deltas[0]\n",
    "\n",
    "            \n",
    "            info_passed_to_weights = self.weights[l].T @ deltas[0]   # information from present layer passed on to the weights connecting present and previous layers \n",
    "            if maths.any(maths.isinf(info_passed_to_weights)) :\n",
    "                print(l)\n",
    "                print(deltas[0])\n",
    "                print(self.weights[l])\n",
    "                raise ValueError(\"Infinite values encountered while passing information to weights ! Exploding gradient !!!\")\n",
    "            \n",
    "            if l > 0 : layer = self.hidden_layers[l-1]\n",
    "            else : layer = self.activations[0]\n",
    "\n",
    "            change_in_neurons = maths.matrix([self.calculate_derivative(float(i),self.hidden) for i in layer ]).reshape(-1,1)  # change of neurons of the previous layer\n",
    "\n",
    "            \n",
    "            delta =  maths.multiply(info_passed_to_weights , change_in_neurons ).reshape(-1,1)      # changes in loss wrt the previous layer's neurons\n",
    "            if maths.any(maths.isnan(delta)) :\n",
    "                raise ValueError(\"NaN values encountered in delta\")\n",
    "            deltas.insert(0,delta)\n",
    "\n",
    "            grad_weights.insert(0,grad_weight)\n",
    "            grad_biases.insert(0,grad_bias)\n",
    "    \n",
    "        return grad_weights, grad_biases\n",
    "\n",
    "\n",
    "    def has_converged(self, prev_weights, prev_bias) :\n",
    "        self._converged = (maths.linalg.norm(maths.matrix(self.weights[0]) - maths.matrix(prev_weights[0])) < self.epsilon) and (maths.linalg.norm(maths.matrix(self.bias[0]) - maths.matrix(prev_bias[0])) < self.epsilon)\n",
    "\n",
    "\n",
    "    def update_weights(self):\n",
    "        \n",
    "        prev_weights = [w + 1 for w in self.weights]\n",
    "        prev_bias = [b + 1 for b in self.bias]\n",
    "        \n",
    "        self._converged = False\n",
    "        \n",
    "        while not self._converged:\n",
    "            prev_weights = self.weights.copy()\n",
    "            prev_bias = self.bias.copy()\n",
    "\n",
    "            number_of_batches = len(self.df_data) // self.batch_size\n",
    "\n",
    "            for M in range(number_of_batches) :\n",
    "                batch_grad_weights = []\n",
    "                batch_grad_bias = []\n",
    "                for m in range(self.batch_size) :\n",
    "                    if min(M*self.batch_size + m , self.N) != self.N :\n",
    "                        x = maths.matrix(self.df_data.iloc[M*self.batch_size + m][:-1]).reshape(-1,1)\n",
    "                        y = self.df_data.iloc[M*self.batch_size + m][-1]\n",
    "                        self.forward_propagation(x)\n",
    "                        grad_weights, grad_bias = self.backward_propagation(x,y)\n",
    "                        batch_grad_weights.append(grad_weights)\n",
    "                        batch_grad_bias.append(grad_bias)\n",
    "                \n",
    "                self.sum_of_grad_bias = batch_grad_bias[0].copy()\n",
    "                self.sum_of_grad_weights = batch_grad_weights[0].copy()\n",
    "\n",
    "                \n",
    "                for i in range(1,len(batch_grad_bias)):\n",
    "                    for j in range(len(batch_grad_bias[i])):\n",
    "                        self.sum_of_grad_bias[j] = self.sum_of_grad_bias[j] + batch_grad_bias[i][j]\n",
    "\n",
    "                for i in range(1,len(batch_grad_weights)):\n",
    "                    for j in range(len(batch_grad_weights[i])):\n",
    "                        self.sum_of_grad_weights[j] = self.sum_of_grad_weights[j] + batch_grad_weights[i][j]\n",
    "                        \n",
    "                \n",
    "                for l in range(self.number_of_hidden_layers + 1) :\n",
    "                    self.weights[l] = self.weights[l] - float(self.alpha/self.batch_size) * self.sum_of_grad_weights[l]\n",
    "                    self.bias[l] = self.bias[l] - float(self.alpha/self.batch_size) * self.sum_of_grad_bias[l]\n",
    "                        \n",
    "            \n",
    "            self.has_converged(prev_weights, prev_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5471e1cf-4c75-4c5c-96e9-28ea9259949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_in_each_layer = [2,1]\n",
    "epsilon = 1e-3\n",
    "alpha = 0.001\n",
    "hidden_function = 'relu'\n",
    "output_function = 'identity'\n",
    "initialise_through = 'xavier_normal'\n",
    "\n",
    "\n",
    "ann = neural_network(df_data ,\n",
    "                     number_of_neurons = neurons_in_each_layer,\n",
    "                     epsilon = epsilon,\n",
    "                     alpha = alpha,\n",
    "                     hidden_function = hidden_function,\n",
    "                     output_function = output_function,\n",
    "                     initialisation_technique = initialise_through, \n",
    "                     batch_size = 1\n",
    "                    )\n",
    "\n",
    "ann.initialisation()\n",
    "ann.update_weights()\n",
    "\n",
    "for i in range(len(neurons_in_each_layer)):\n",
    "    print(\"LAYER\",i+1)\n",
    "    print(\"Weights\")\n",
    "    print(ann.weights[i])\n",
    "    print(\"Bias\")\n",
    "    print(ann.bias[i].T)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
