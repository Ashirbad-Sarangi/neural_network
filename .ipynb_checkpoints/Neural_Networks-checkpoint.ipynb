{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36350b31-f335-440c-bb36-beb2387d208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as analytics\n",
    "import numpy as maths\n",
    "from math import exp\n",
    "from numba import cuda , jit\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c68efa-5602-4bea-a046-92db220cd6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.930</td>\n",
       "      <td>-20.9020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.410</td>\n",
       "      <td>2.0033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-20.686</td>\n",
       "      <td>-33.3030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.974</td>\n",
       "      <td>-13.5550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.965</td>\n",
       "      <td>20.3680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-29.232</td>\n",
       "      <td>28.4410</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-10.159</td>\n",
       "      <td>7.3065</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-32.026</td>\n",
       "      <td>14.9380</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-49.533</td>\n",
       "      <td>-11.1280</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-26.065</td>\n",
       "      <td>33.4200</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0       x1  y\n",
       "0    22.930 -20.9020  1\n",
       "1    12.410   2.0033  1\n",
       "2   -20.686 -33.3030  1\n",
       "3    46.974 -13.5550  1\n",
       "4    41.965  20.3680  1\n",
       "..      ...      ... ..\n",
       "195 -29.232  28.4410 -1\n",
       "196 -10.159   7.3065 -1\n",
       "197 -32.026  14.9380 -1\n",
       "198 -49.533 -11.1280 -1\n",
       "199 -26.065  33.4200 -1\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = analytics.read_csv('data1.csv',header = None , names = ['x0','x1','y'])\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "393dcb48-e0b2-4fe6-9ec8-3c16c51a8e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network :\n",
    "    \n",
    "    def __init__(self,df_data , number_of_neurons = [2,1], epsilon = 5e-2, alpha = 0.2, hidden_function = 'relu', output_function = 'sigmoid') :\n",
    "\n",
    "        # if number_of_hidden_layers + 1 != len(number_of_neurons) :\n",
    "        #     raise ValueError(\"Given structure is not correct ! Number of Hidden Layers stated and Number of neurons in hidden layers are not matching\")\n",
    "        \n",
    "        self.number_of_hidden_layers = len(number_of_neurons) - 1\n",
    "        self.number_of_neurons = number_of_neurons\n",
    "        self.df_data = df_data\n",
    "        self.epsilon = epsilon \n",
    "        self.N = df_data.shape[0]\n",
    "        self.alpha = alpha\n",
    "\n",
    "        functions_list = {'relu':self.relu , 'sigmoid' : self.sigmoid}\n",
    "        self.hidden = functions_list[hidden_function]\n",
    "        self.output = functions_list[output_function]\n",
    "\n",
    "\n",
    "    def relu(self,x) :\n",
    "        \"\"\"Hidden Activation Function\"\"\"\n",
    "        return max(0,x)\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        \"\"\"Output Function\"\"\"\n",
    "        return 1 / (1 + exp(-x))\n",
    "\n",
    "    def calculate_derivative(self, data, func):\n",
    "        if func == self.relu :\n",
    "            if data > 0 : data = 1\n",
    "            derivative = func(data)\n",
    "\n",
    "        if func == self.sigmoid :\n",
    "            derivative = func(data) * ( 1- func(data))\n",
    "\n",
    "        return derivative\n",
    "\n",
    "    \n",
    "    def initialisation(self):\n",
    "        weights = []\n",
    "        bias = []\n",
    "        for l in range(self.number_of_hidden_layers + 1):\n",
    "            if l == 0 : previous_layer = df_data.shape[1] - 1\n",
    "            else : previous_layer = self.number_of_neurons[l-1]\n",
    "            present_layer = self.number_of_neurons[l]\n",
    "            weights.append(maths.random.random((present_layer,previous_layer)))\n",
    "            bias.append(maths.random.random((present_layer,1)))\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "\n",
    "    def forward_propagation(self,x):\n",
    "        activations = []\n",
    "        activations.append(x)   # inputdata point is the initial activation\n",
    "        \n",
    "        hidden_layers = []\n",
    "        \n",
    "        for l in range(self.number_of_hidden_layers):\n",
    "            neurons = self.weights[l] @ activations[l] + self.bias[l]   # it actually should be activations[l+1] but because indexing in python starts from 0, so it is activations[l]\n",
    "            activation = maths.matrix([self.hidden(float(neuron)) for neuron in neurons]).reshape(-1,1)\n",
    "            hidden_layers.append(neurons)\n",
    "            activations.append(activation)\n",
    "   \n",
    "        data = self.weights[-1] @ activations[-1] + self.bias[-1]\n",
    "        activations.append(self.output(data))\n",
    "        \n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.activations = activations\n",
    "\n",
    "\n",
    "    def backward_propagation(self) :\n",
    "      \n",
    "        deltas = []\n",
    "        data = self.weights[-1] @ self.activations[-2] + self.bias[-1]\n",
    "        diff_loss_wrt_output = self.activations[-1]\n",
    "        delta = maths.matrix(maths.multiply(diff_loss_wrt_output,  self.calculate_derivative(data,self.output))).reshape(-1,1)\n",
    "        deltas.append(delta)\n",
    "        \n",
    "        grad_weights = []\n",
    "        grad_biases = []\n",
    "        for l in range(self.number_of_hidden_layers , -1, -1 ): # it is actually running from Output layer to the first hidden layer. Due to indexing convention, loop starts from number_of_hidden_layers and goes till 0\n",
    "            grad_weight = deltas[0] @ self.activations[l].T\n",
    "            grad_bias = deltas[0]\n",
    "\n",
    "            d = self.weights[l].T @ deltas[0]\n",
    "            der = maths.matrix([self.calculate_derivative(float(i),self.hidden) for i in self.hidden_layers[l-1]]).reshape(-1,1)\n",
    "            delta = maths.multiply( d , der ).reshape(-1,1)\n",
    "            deltas.insert(0,delta)\n",
    "\n",
    "            grad_weights.insert(0,grad_weight)\n",
    "            grad_biases.insert(0,grad_bias)\n",
    "    \n",
    "        return grad_weights, grad_biases\n",
    "\n",
    "\n",
    "    def has_converged(self, prev_weights, prev_bias) :\n",
    "        self._converged = (maths.linalg.norm(maths.matrix(self.weights[0]) - maths.matrix(prev_weights[0])) < self.epsilon) and (maths.linalg.norm(maths.matrix(self.bias[0]) - maths.matrix(prev_bias[0])) < self.epsilon)\n",
    "\n",
    "\n",
    "    def update_weights(self):\n",
    "        \n",
    "        prev_weights = [w + 1 for w in self.weights]\n",
    "        prev_bias = [b + 1 for b in self.bias]\n",
    "        \n",
    "        self._converged = False\n",
    "        \n",
    "        while not self._converged:\n",
    "            prev_weights = self.weights.copy()\n",
    "            prev_bias = self.bias.copy()\n",
    "            \n",
    "            for m in range(self.N) :\n",
    "                x = maths.matrix(self.df_data.iloc[m][:-1]).reshape(-1,1)\n",
    "                y = self.df_data.iloc[m][-1]\n",
    "                self.forward_propagation(x)\n",
    "                grad_weights, grad_bias = self.backward_propagation()\n",
    "\n",
    "                for l in range(self.number_of_hidden_layers + 1) :\n",
    "                    self.weights[l] = self.weights[l] - self.alpha/self.N * grad_weights[l]\n",
    "                    self.bias[l] = self.bias[l] - self.alpha/self.N * grad_bias[l]\n",
    "                    \n",
    "            \n",
    "            self.has_converged(prev_weights, prev_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5471e1cf-4c75-4c5c-96e9-28ea9259949d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER 1\n",
      "Weights\n",
      "[[0.93844702 0.84165307]\n",
      " [0.49173185 0.4141079 ]\n",
      " [0.56771668 0.23704826]\n",
      " [0.72262624 0.09342932]\n",
      " [0.3993574  0.01305375]]\n",
      "Bias\n",
      "[[0.67198154 0.61487117 0.30290067 0.83504981 0.99293454]]\n",
      "\n",
      "LAYER 2\n",
      "Weights\n",
      "[[0.12872233 0.48148709 0.14455145 0.10016372 0.63148733]\n",
      " [0.43418351 0.36104668 0.7122866  0.51279804 0.77343812]\n",
      " [0.17235311 0.71760145 0.12182123 0.91683855 0.86996805]]\n",
      "Bias\n",
      "[[0.69267888 0.13546792 0.27159113]]\n",
      "\n",
      "LAYER 3\n",
      "Weights\n",
      "[[0.87515209 0.18885136 0.8931342 ]\n",
      " [0.77698471 0.52808508 0.50576448]\n",
      " [0.14259524 0.30623374 0.9653051 ]\n",
      " [0.65597982 0.66142878 0.48521389]\n",
      " [0.5623395  0.55239742 0.37136989]]\n",
      "Bias\n",
      "[[0.11754939 0.33368122 0.28752836 0.74304545 0.70793896]]\n",
      "\n",
      "LAYER 4\n",
      "Weights\n",
      "[[0.56486568 0.18096658 0.65559309 0.92291038 0.84322655]\n",
      " [0.95786665 0.98938328 0.68856124 0.17394717 0.14821441]]\n",
      "Bias\n",
      "[[0.38841874 0.61866499]]\n",
      "\n",
      "LAYER 5\n",
      "Weights\n",
      "[[0.79615602 0.08760867]]\n",
      "Bias\n",
      "[[0.64117347]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neurons_in_each_layer = [5,3,5,2,1]\n",
    "epsilon = 5e-2\n",
    "alpha = 0.2\n",
    "hidden_function = 'relu'\n",
    "output_function = 'sigmoid'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ann = neural_network(df_data ,\n",
    "                     number_of_neurons = neurons_in_each_layer,\n",
    "                     epsilon = epsilon,\n",
    "                     alpha = alpha,\n",
    "                     hidden_function = hidden_function,\n",
    "                     output_function = output_function\n",
    "                    )\n",
    "\n",
    "ann.initialisation()\n",
    "ann.update_weights()\n",
    "\n",
    "for i in range(len(neurons_in_each_layer)):\n",
    "    print(\"LAYER\",i+1)\n",
    "    print(\"Weights\")\n",
    "    print(ann.weights[i])\n",
    "    print(\"Bias\")\n",
    "    print(ann.bias[i].T)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
